{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Analyzing, Filtering, and Cleaning Aviation Database for the Safest Plane\n",
    "by Allison Ward, Rick Lataille, and Anthony Mansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Goal: \n",
    "This analysis will idenify those planes with the lowest risk for the U.S. domestic flights market\n",
    "\n",
    "\n",
    "### Data Source: \n",
    "This data is sourced from the National Transportation Safety Boardâ€™s (NTSB) Aviation Accident data set from 1962 to 2023. The data contains information regarding civil aviation accidents and selected incidents in the United States and international waters. The raw data set inclues ~90,000 rows of safety-related occurrences involving all types of aircrafts. \n",
    "\n",
    "### Limitations:\n",
    "The dataset was provided by The Flatiron School and contains impurities compared to the dataset available directly from the NTSB. It only shows planes in accidents with no information on flights that were completed without incident.  It does not differentiate between hardware failures and pilot error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import\n",
    "First import pandas and numpy and import the data into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the modules we need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# And this is the big data that we will be using\n",
    "df = pd.read_csv('data/Aviation_Data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns\n",
    "Many columns in the dataset are unnecessary for this analysis and can be dropped to reduce the size of the file.  Then print the number of items for later reference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90348 items.\n"
     ]
    }
   ],
   "source": [
    "# Drop the columns we know that we don't need\n",
    "dropped_columns = ['Event.Id', 'Investigation.Type', 'Accident.Number', 'Airport.Code', 'Airport.Name', \\\n",
    "                   'Aircraft.damage', 'Registration.Number', 'Model', 'FAR.Description', \\\n",
    "                   'Schedule', 'Air.carrier', 'Weather.Condition', 'Broad.phase.of.flight', 'Report.Status', \\\n",
    "                   'Publication.Date']\n",
    "df.drop(columns = dropped_columns, inplace=True)\n",
    "print(f\"{len(df)} items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter columns \n",
    "StellarSkies is focused on starting a major airline operating only in the US domestic market for commercial and business flights, so certain types of incidents can be excluded, including:\n",
    "\n",
    "* Incidents occurring prior to 2013; since then incidents have maintained a consistent level after several decades of declines\n",
    "* Incidents involving non-airplane aircraft\n",
    "* Incidents involving amateur-built aircraft\n",
    "* International flights\n",
    "* Incidents that occurred while undertaking atypical purposes, such as firefighting, crop-dusting, test flights, etc.\n",
    "* Incidents that are incorrectly coded as relevant, or with data that is insufficient to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding pre-2013 incidents results in 15829 items.\n",
      "Excluding non-airplane incidents results in 13262 items.\n",
      "Excluding amateur-built planes results in 11726 items.\n",
      "Excluding irrelevant purposes results in 9497 items.\n",
      "Excluding non-US flights results in 7320 items.\n",
      "Excluding foreign flight artifacts results in 7307 items.\n",
      "Excluding flights with missing geographic data results in 7302 items.\n"
     ]
    }
   ],
   "source": [
    "# Convert date column to datetime, then filter event dates to include 2013 and later\n",
    "df['Event.Date'] = pd.to_datetime(df['Event.Date'])\n",
    "df_filtered = df.loc[df['Event.Date'] >= '2013-01-01']\n",
    "print(f\"Excluding pre-2013 incidents results in {len(df_filtered)} items.\")\n",
    "\n",
    "# Filter aircraft categories for Airplanes only\n",
    "df_filtered = df_filtered.loc[df_filtered['Aircraft.Category'] == 'Airplane']\n",
    "print(f\"Excluding non-airplane incidents results in {len(df_filtered)} items.\")\n",
    "\n",
    "# Exclude Amateur-built planes\n",
    "df_filtered = df_filtered.loc[df_filtered['Amateur.Built'] != 'Yes']\n",
    "print(f\"Excluding amateur-built planes results in {len(df_filtered)} items.\")\n",
    "\n",
    "# Exclude certain identified purposes as irrelevant to our stakeholder\n",
    "allowed_purposes = ['Personal', np.nan, 'Business', 'Executive/corporate', \\\n",
    "                    'Positioning', 'Other Work Use', 'Ferry', 'Unknown', 'Public Aircraft - Federal', \\\n",
    "                   'Public Aircraft - State', 'Public Aircraft - Local', 'Public Aircraft', 'PUBS']\n",
    "df_filtered = df_filtered.loc[df_filtered['Purpose.of.flight'].isin(allowed_purposes)]\n",
    "print(f\"Excluding irrelevant purposes results in {len(df_filtered)} items.\")\n",
    "\n",
    "# Include only events that happened in the United States or US Territories\n",
    "allowed_countries = ['United States']\n",
    "df_filtered = df_filtered.loc[df_filtered['Country'].isin(allowed_countries)]\n",
    "print(f\"Excluding non-US flights results in {len(df_filtered)} items.\")\n",
    "\n",
    "# Filter for foreign locations not noted as foreign using the 'OF' state code in Location\n",
    "df_filtered['State_Code'] = df_filtered['Location'].str.slice(-2)\n",
    "df_filtered = df_filtered.loc[df_filtered['State_Code'] != 'OF']\n",
    "print(f\"Excluding foreign flight artifacts results in {len(df_filtered)} items.\")\n",
    "\n",
    "# Drop rows that are missing latitude coordinates (also captures missing Longitude)\n",
    "df_filtered.dropna(subset=['Latitude'], inplace=True)\n",
    "print(f\"Excluding flights with missing geographic data results in {len(df_filtered)} items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation\n",
    "Several new columns will simplify the analysis for the safety, large jets and small jets analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use dt functions to extract year, month and day of week and create new columns\n",
    "df_filtered['Year'] = df['Event.Date'].dt.year\n",
    "df_filtered['Month'] = df['Event.Date'].dt.month\n",
    "df_filtered['Day_Of_Week'] = df['Event.Date'].dt.day_name()\n",
    "\n",
    "# Create a new column to simplify the large jet analysis\n",
    "separate_large_jets = [\"Airbus\", \"Boeing\", \"Embraer\"]\n",
    "df_filtered['Large_Jets'] = df_filtered['Make'].map(lambda x: \"Other\" if x not in separate_large_jets else x)\n",
    "\n",
    "# Create a new column to simplify the large jet analysis\n",
    "separate_small_jets = [\"Bombardier\", \"Dassault\", \"Gulfstream\", \"Honda\", \"Textron\"]\n",
    "df_filtered['Small_Jets'] = df_filtered['Make'].map(lambda x: \"Other\" if x not in separate_small_jets else x)\n",
    "\n",
    "# Create a new column summing fatal and serious injuries\n",
    "df_filtered['Major_Injuries'] = df_filtered['Total.Fatal.Injuries'] + df_filtered['Total.Serious.Injuries']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once those filters are applied, several more columns can be dropped since they are no longer relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are no longer useful\n",
    "obsolete_columns = ['Event.Date', 'Location', 'Country', 'Aircraft.Category', 'Amateur.Built']\n",
    "df_filtered.drop(columns = obsolete_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidating Makes\n",
    "Entries in the make column reflect manual data entries that must be cleaned in order to accurately reflect the current manufacturer.  The consolidation is limited to the major participants in the commercial and business markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record original makes for later comparison\n",
    "Original_makes = len(df_filtered['Make'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These map functions will clean the 'Make' column to focus on the makes in our analysis\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Airbus\" if x.lower().strip()[:6]==\"airbus\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Airbus\" if x.lower().strip()[:5]==\"fouga\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Boeing\" if x.lower().strip()[:6]==\"boeing\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Boeing\" if x.lower().strip()[:9]==\"mcdonnell\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Boeing\" if x.lower().strip()[:7]==\"douglas\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Boeing\" if x.lower().strip()[:8]==\"rockwell\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Bombardier\" if x.lower().strip()[:10]==\"bombardier\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Bombardier\" if x.lower().strip()[:5]==\"gates\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Bombardier\" if x.lower().strip()[:7]==\"learjet\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Bombardier\" if x.lower().strip()[:8]==\"canadair\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Dassault\" if x.lower().strip()[:8]==\"dassault\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Embraer\" if x.lower().strip()[:7]==\"embraer\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Gulfstream\" if x.lower().strip()[:10]==\"gulfstream\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Gulfstream\" if x.lower().strip()[:3]==\"iai\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Honda\" if x.lower().strip()[:5]==\"honda\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:6]==\"cessna\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:4]==\"rath\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:4]==\"rayt\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:7]==\"textron\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:5]==\"beech\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:6]==\"hawker\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original 670 makes have been reduced to 595 makes.\n"
     ]
    }
   ],
   "source": [
    "# Show the amount of consolidation in makes\n",
    "print(f\"The original {Original_makes} makes have been reduced to {len(df_filtered['Make'].unique())} makes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing unknown values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change \"NaN\" to 'None' or 'Unknown', as appropriate\n",
    "df_filtered['Injury.Severity'].fillna('None', inplace=True)\n",
    "df_filtered['Purpose.of.flight'].fillna('Unknown', inplace=True)\n",
    "df_filtered['Engine.Type'].fillna('Unknown', inplace=True)\n",
    "df_filtered['Number.of.Engines'].fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert entries in the 'Make' column to Title case for readability in the visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all Makes into Title case, for readability\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: x.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalize Filtered Data\n",
    "Save the now-filtered data to a new CSV file which:\n",
    "* preserves the information in the raw data file for later re-use or confirmation\n",
    "* creates a new, smaller data file for use in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a new CSV file/overwrites CSV file\n",
    "df_filtered.to_csv('data/Filtered_Aviation_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This analysis shows:\n",
    "1. Reciprocating engines and single-engine planes present the biggest risk of major injury and should be avoided.\n",
    "2. Boeing, Cessna and Bombardier have worse safety records than Airbus, Embraer, Gulfstream and Dassault.\n",
    "3. Lastly, summers and weekends are more dangerous and protocols should be set in place keeping this in mind."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
