{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940ed68a",
   "metadata": {},
   "source": [
    "  # Analyzing, Filtering, and Cleaning Aviation Database for the Safest Plane\n",
    "                                          Jupyter Notebook coded by Allison Ward, Rick Lataille, and Anthony Mansion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75486aa",
   "metadata": {},
   "source": [
    "### As usual, imported pandas to manage big data, as well as numpy for future statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d16767fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the modules we need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# And this is the big data that we will be using\n",
    "df = pd.read_csv('Aviation_Data.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9352a214",
   "metadata": {},
   "source": [
    "### Here, we will be dropping columns we see no need for, the information isn't relevant. These columns are dropped because the information it provides has no use in finding the results our stakeholder is looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c96a51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90348 items.\n"
     ]
    }
   ],
   "source": [
    "# Drop the columns we know that we don't need\n",
    "dropped_columns = ['Schedule', 'Report.Status', 'Publication.Date']\n",
    "df.drop(columns = dropped_columns, inplace=True)\n",
    "print(f\"{len(df)} items.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfe65fa",
   "metadata": {},
   "source": [
    "### Now looking at the rest of the columns, we filter some columns for the information we need. We leave the original \"df\" alone and instead make another variable to hold our filtered information. The ways we filtered were: filtering for rows with data from the last 10 years, filter data for aircrafts to airplanes only since that's the data we will be using, exclude the rows for planes that are amateur built since they... kind of screw the results we need over, and lastly filtering for the United States only. Filtering for the U.S. only is mainly because the rows that aren't in here aren't filled and can't tell of anything, and it even the same case for the U.S. territories that aren't between the Altantic and Pacific Oceans. Dropped from about 90,000 items to 7,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "939129c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15829 items.\n",
      "13262 items.\n",
      "11726 items.\n",
      "9497 items.\n",
      "7320 items.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mansi\\AppData\\Local\\Temp\\ipykernel_27536\\4153400819.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered['Day_Of_Week'] = df['Event.Date'].dt.day_name()\n"
     ]
    }
   ],
   "source": [
    "# Convert date column to datetime, then filter event dates to include 2013 and later\n",
    "df['Event.Date'] = pd.to_datetime(df['Event.Date'])\n",
    "df_filtered = df.loc[df['Event.Date'] >= '2013-01-01']\n",
    "print(f\"{len(df_filtered)} items.\")\n",
    "\n",
    "# Creating a new column with Day of Week\n",
    "df_filtered['Day_Of_Week'] = df['Event.Date'].dt.day_name()\n",
    "\n",
    "# Filter aircraft categories for Airplanes only\n",
    "df_filtered = df_filtered.loc[df_filtered['Aircraft.Category'] == 'Airplane']\n",
    "print(f\"{len(df_filtered)} items.\")\n",
    "\n",
    "# Exclude Amateur-built planes\n",
    "df_filtered = df_filtered.loc[df_filtered['Amateur.Built'] != 'Yes']\n",
    "print(f\"{len(df_filtered)} items.\")\n",
    "\n",
    "# Exclude certain identified purposes as irrelevant to our stakeholder\n",
    "allowed_purposes = ['Personal', np.nan, 'Business', 'Executive/corporate', \\\n",
    "                    'Positioning', 'Other Work Use', 'Ferry', 'Unknown', 'Public Aircraft - Federal', \\\n",
    "                   'Public Aircraft - State', 'Public Aircraft - Local', 'Public Aircraft', 'PUBS']\n",
    "df_filtered = df_filtered.loc[df_filtered['Purpose.of.flight'].isin(allowed_purposes)]\n",
    "print(f\"{len(df_filtered)} items.\")\n",
    "\n",
    "# Include only events that happened in the United States or US Territories\n",
    "allowed_countries = ['United States']\n",
    "df_filtered = df_filtered.loc[df_filtered['Country'].isin(allowed_countries)]\n",
    "print(f\"{len(df_filtered)} items.\")\n",
    "\n",
    "# Drop even more columns that are no longer useful\n",
    "obsolete_columns = ['Event.Id', 'Country', 'Aircraft.Category', 'Registration.Number', 'Broad.phase.of.flight']\n",
    "df_filtered.drop(columns = obsolete_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b88a0d",
   "metadata": {},
   "source": [
    "### With all that filtered data, saved it to a new csv file for an even easier time making visualizations of the data since all the info we need won't be surrounded by the other  random information. We also did this instead of overwriting the original \"just in case\", y'know? Just in case we wanted to undo something, we could simply overwrite the csv and throw it back into Tableau real fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8bb1136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The new filtered dataframe of the original dataframe \"df\"\n",
    "df_filtered.to_csv('Filtered_Aviation_Data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9ed57d",
   "metadata": {},
   "source": [
    "## The test of death. (Honestly, this whole part is irrelevant and would have been 1,000 times easier and waaaay more efficient rather than \"hard-coding\" it. ðŸ˜” But the lines have already written, so we just had to see it through...) The test here is grabbing many random categories, and using those to make comparisons between other random categories. I was going to then import matplotlib to begin making visualizations, but I already realized how unefficient I was working and the time I was wasting when I could have just thrown the csv in Tableau... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe989c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell block below, I will do even further filtering to whittle down numbers and find the best plane\n",
    "# The filters will be based on how safe they are, so how less they repeat by finding: the number of engines that\n",
    "# appear the least, the type of engine that appears the least, non-fatal injuries, substantial damage to plane\n",
    "\n",
    "# First, made a copy of the current filtered datamframe to filter even more\n",
    "# Filtering by injuries to see comparisons between resullts\n",
    "Fatal_Inj = df.loc[df['Total.Fatal.Injuries'] > 0]\n",
    "Serious_Inj = df.loc[df['Total.Serious.Injuries'] > 0]\n",
    "Minor_Inj = df.loc[df['Total.Minor.Injuries'] > 0]\n",
    "Uninjured = df.loc[(df['Total.Uninjured'] > 0) & (df['Total.Minor.Injuries'] == 0)] \n",
    "\n",
    "# Hmm... lets see the difference between substantial damage, too\n",
    "Sub_Damage = df.loc[df['Aircraft.damage'] == 'Substantial'] # (Substantial Damage)\n",
    "Destroyed = df.loc[df['Aircraft.damage'] == 'Destroyed'] # (Destroyed planes)\n",
    "Minor_Damage = df.loc[df['Aircraft.damage'] == 'Minor']            \n",
    "\n",
    "# Looking at the difference between data using engine types as well\n",
    "Reciprocating_Eng = df.loc[df['Engine.Type'] == 'Reciprocating'] \n",
    "Turbo_Shaft = df.loc[df['Engine.Type'] == 'Turbo Shaft']\n",
    "Turbo_Prop = df.loc[df['Engine.Type'] == 'Turbo Prop']\n",
    "Turbo_Fan = df.loc[df['Engine.Type'] == 'Turbo Fan']\n",
    "Turbo_Jet = df.loc[df['Engine.Type'] == 'Turbo Jet']\n",
    "Geared_Turbofan = df.loc[df['Engine.Type'] == 'Geared Turbofan']\n",
    "Electric = df.loc[df['Engine.Type'] == 'Electric']\n",
    "LR = df.loc[df['Engine.Type'] == 'LR'] \n",
    "NONE = df.loc[df['Engine.Type'] == 'NONE'] \n",
    "Hyrbrid_Rocket = df.loc[df['Engine.Type'] == 'Hyrbrid Rocket'] \n",
    "UNK = df.loc[df['Engine.Type'] == 'UNK']\n",
    "\n",
    "# Seeing if there are different results using the number of engines, too\n",
    "NO_ENGINES = df.loc[df['Number.of.Engines'] == 0] #??!!\n",
    "One_Engine = df.loc[df['Number.of.Engines'] == 1] \n",
    "Two_Engines = df.loc[df['Number.of.Engines'] == 2] \n",
    "Three_Engines = df.loc[df['Number.of.Engines'] == 3] \n",
    "Four_Engines = df.loc[df['Number.of.Engines'] == 4] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11da8ac",
   "metadata": {},
   "source": [
    "### Now at this point is when we WOULD HAVE imported matplotlib, but we already realized a few lines into the cell block above that we were just wasting time and that it'd be better to just use Tableau. But below, I made a third corny variable (which is why the name is very bad lol) to become the dataframe that will be used for comparisons. But in order to compare each, I have to reset the new variable by making it the old dataframe each time or it will just get smaller and smaller. (Just realized we didn't even use those variables above, haha...ðŸ˜­)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b0419df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Investigation.Type</th>\n",
       "      <th>Accident.Number</th>\n",
       "      <th>Event.Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Airport.Code</th>\n",
       "      <th>Airport.Name</th>\n",
       "      <th>Injury.Severity</th>\n",
       "      <th>Aircraft.damage</th>\n",
       "      <th>...</th>\n",
       "      <th>Engine.Type</th>\n",
       "      <th>FAR.Description</th>\n",
       "      <th>Purpose.of.flight</th>\n",
       "      <th>Air.carrier</th>\n",
       "      <th>Total.Fatal.Injuries</th>\n",
       "      <th>Total.Serious.Injuries</th>\n",
       "      <th>Total.Minor.Injuries</th>\n",
       "      <th>Total.Uninjured</th>\n",
       "      <th>Weather.Condition</th>\n",
       "      <th>Day_Of_Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73204</th>\n",
       "      <td>Accident</td>\n",
       "      <td>CEN13CA129</td>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>Alexandria, MN</td>\n",
       "      <td>455145N</td>\n",
       "      <td>0095240W</td>\n",
       "      <td>AXN</td>\n",
       "      <td>Alexindria Municipal Airport</td>\n",
       "      <td>Non-Fatal</td>\n",
       "      <td>Substantial</td>\n",
       "      <td>...</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BEMIDJI AVIATION SERVICES INC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>IMC</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73286</th>\n",
       "      <td>Accident</td>\n",
       "      <td>ERA13LA129</td>\n",
       "      <td>2013-02-07</td>\n",
       "      <td>Winston-Salem, NC</td>\n",
       "      <td>003681N</td>\n",
       "      <td>0801319W</td>\n",
       "      <td>INT</td>\n",
       "      <td>Smith Reynolds Airport</td>\n",
       "      <td>Non-Fatal</td>\n",
       "      <td>Substantial</td>\n",
       "      <td>...</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>091</td>\n",
       "      <td>Personal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>VMC</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73313</th>\n",
       "      <td>Accident</td>\n",
       "      <td>CEN13CA162</td>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>323031N</td>\n",
       "      <td>0993626W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Fatal</td>\n",
       "      <td>Substantial</td>\n",
       "      <td>...</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>091</td>\n",
       "      <td>Business</td>\n",
       "      <td>FRANK LEROY BELL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>VMC</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73321</th>\n",
       "      <td>Accident</td>\n",
       "      <td>ANC13CA023</td>\n",
       "      <td>2013-02-16</td>\n",
       "      <td>Dutch Harbor, AK</td>\n",
       "      <td>535334N</td>\n",
       "      <td>1663225W</td>\n",
       "      <td>PADU</td>\n",
       "      <td>Unalaska</td>\n",
       "      <td>Non-Fatal</td>\n",
       "      <td>Substantial</td>\n",
       "      <td>...</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRANT AVIATION INC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>VMC</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73329</th>\n",
       "      <td>Accident</td>\n",
       "      <td>WPR13LA132</td>\n",
       "      <td>2013-02-17</td>\n",
       "      <td>Casper, WY</td>\n",
       "      <td>425417N</td>\n",
       "      <td>1062731W</td>\n",
       "      <td>CPR</td>\n",
       "      <td>Casper/Natrona County Int'l</td>\n",
       "      <td>Non-Fatal</td>\n",
       "      <td>Substantial</td>\n",
       "      <td>...</td>\n",
       "      <td>Reciprocating</td>\n",
       "      <td>091</td>\n",
       "      <td>Personal</td>\n",
       "      <td>BRAVENEC DANIEL W</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VMC</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90275</th>\n",
       "      <td>Accident</td>\n",
       "      <td>CEN23LA052</td>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>Denton, TX</td>\n",
       "      <td>292548N</td>\n",
       "      <td>1005924W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Fatal</td>\n",
       "      <td>Substantial</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>091</td>\n",
       "      <td>Personal</td>\n",
       "      <td>Pilot</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90293</th>\n",
       "      <td>Accident</td>\n",
       "      <td>CEN23LA056</td>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>Batesville, AR</td>\n",
       "      <td>354334N</td>\n",
       "      <td>0913851W</td>\n",
       "      <td>BVX</td>\n",
       "      <td>Batesville Regional Airport</td>\n",
       "      <td>Minor</td>\n",
       "      <td>Substantial</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>091</td>\n",
       "      <td>Business</td>\n",
       "      <td>Creamer Pilot Services LLC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>IMC</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90295</th>\n",
       "      <td>Accident</td>\n",
       "      <td>ERA23LA075</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>Newport News, VA</td>\n",
       "      <td>037816N</td>\n",
       "      <td>0762838W</td>\n",
       "      <td>PHF</td>\n",
       "      <td>NEWPORT NEWS/WILLIAMSBURG INTL</td>\n",
       "      <td>Non-Fatal</td>\n",
       "      <td>Substantial</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>091</td>\n",
       "      <td>Other Work Use</td>\n",
       "      <td>AERY AVIATION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>VMC</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90328</th>\n",
       "      <td>Accident</td>\n",
       "      <td>WPR23LA065</td>\n",
       "      <td>2022-12-13</td>\n",
       "      <td>Lewistown, MT</td>\n",
       "      <td>047257N</td>\n",
       "      <td>0109280W</td>\n",
       "      <td>KLWT</td>\n",
       "      <td>Lewiston Municipal Airport</td>\n",
       "      <td>Non-Fatal</td>\n",
       "      <td>Substantial</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NUSC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90335</th>\n",
       "      <td>Accident</td>\n",
       "      <td>WPR23LA069</td>\n",
       "      <td>2022-12-15</td>\n",
       "      <td>Wichita, KS</td>\n",
       "      <td>373829N</td>\n",
       "      <td>0972635W</td>\n",
       "      <td>ICT</td>\n",
       "      <td>WICHITA DWIGHT D EISENHOWER NT</td>\n",
       "      <td>Non-Fatal</td>\n",
       "      <td>Substantial</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>489 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Investigation.Type Accident.Number Event.Date           Location  \\\n",
       "73204           Accident      CEN13CA129 2013-01-11     Alexandria, MN   \n",
       "73286           Accident      ERA13LA129 2013-02-07  Winston-Salem, NC   \n",
       "73313           Accident      CEN13CA162 2013-02-14        Abilene, TX   \n",
       "73321           Accident      ANC13CA023 2013-02-16   Dutch Harbor, AK   \n",
       "73329           Accident      WPR13LA132 2013-02-17         Casper, WY   \n",
       "...                  ...             ...        ...                ...   \n",
       "90275           Accident      CEN23LA052 2022-11-22         Denton, TX   \n",
       "90293           Accident      CEN23LA056 2022-11-29     Batesville, AR   \n",
       "90295           Accident      ERA23LA075 2022-11-30   Newport News, VA   \n",
       "90328           Accident      WPR23LA065 2022-12-13      Lewistown, MT   \n",
       "90335           Accident      WPR23LA069 2022-12-15        Wichita, KS   \n",
       "\n",
       "      Latitude Longitude Airport.Code                    Airport.Name  \\\n",
       "73204  455145N  0095240W          AXN    Alexindria Municipal Airport   \n",
       "73286  003681N  0801319W          INT          Smith Reynolds Airport   \n",
       "73313  323031N  0993626W          NaN                             NaN   \n",
       "73321  535334N  1663225W         PADU                        Unalaska   \n",
       "73329  425417N  1062731W          CPR     Casper/Natrona County Int'l   \n",
       "...        ...       ...          ...                             ...   \n",
       "90275  292548N  1005924W          NaN                             NaN   \n",
       "90293  354334N  0913851W          BVX     Batesville Regional Airport   \n",
       "90295  037816N  0762838W          PHF  NEWPORT NEWS/WILLIAMSBURG INTL   \n",
       "90328  047257N  0109280W         KLWT      Lewiston Municipal Airport   \n",
       "90335  373829N  0972635W          ICT  WICHITA DWIGHT D EISENHOWER NT   \n",
       "\n",
       "      Injury.Severity Aircraft.damage  ...    Engine.Type FAR.Description  \\\n",
       "73204       Non-Fatal     Substantial  ...  Reciprocating             135   \n",
       "73286       Non-Fatal     Substantial  ...  Reciprocating             091   \n",
       "73313       Non-Fatal     Substantial  ...  Reciprocating             091   \n",
       "73321       Non-Fatal     Substantial  ...  Reciprocating             135   \n",
       "73329       Non-Fatal     Substantial  ...  Reciprocating             091   \n",
       "...               ...             ...  ...            ...             ...   \n",
       "90275       Non-Fatal     Substantial  ...            NaN             091   \n",
       "90293           Minor     Substantial  ...            NaN             091   \n",
       "90295       Non-Fatal     Substantial  ...            NaN             091   \n",
       "90328       Non-Fatal     Substantial  ...            NaN            NUSC   \n",
       "90335       Non-Fatal     Substantial  ...            NaN             135   \n",
       "\n",
       "      Purpose.of.flight                    Air.carrier Total.Fatal.Injuries  \\\n",
       "73204               NaN  BEMIDJI AVIATION SERVICES INC                  0.0   \n",
       "73286          Personal                            NaN                  0.0   \n",
       "73313          Business               FRANK LEROY BELL                  0.0   \n",
       "73321               NaN             GRANT AVIATION INC                  0.0   \n",
       "73329          Personal              BRAVENEC DANIEL W                  0.0   \n",
       "...                 ...                            ...                  ...   \n",
       "90275          Personal                          Pilot                  0.0   \n",
       "90293          Business     Creamer Pilot Services LLC                  0.0   \n",
       "90295    Other Work Use                  AERY AVIATION                  0.0   \n",
       "90328               NaN                            NaN                  0.0   \n",
       "90335               NaN                            NaN                  0.0   \n",
       "\n",
       "      Total.Serious.Injuries Total.Minor.Injuries Total.Uninjured  \\\n",
       "73204                    0.0                  0.0             1.0   \n",
       "73286                    0.0                  0.0             3.0   \n",
       "73313                    0.0                  0.0             1.0   \n",
       "73321                    0.0                  0.0             3.0   \n",
       "73329                    0.0                  0.0             2.0   \n",
       "...                      ...                  ...             ...   \n",
       "90275                    0.0                  0.0             7.0   \n",
       "90293                    2.0                  0.0             6.0   \n",
       "90295                    0.0                  0.0             3.0   \n",
       "90328                    0.0                  0.0             1.0   \n",
       "90335                    0.0                  0.0             1.0   \n",
       "\n",
       "       Weather.Condition  Day_Of_Week  \n",
       "73204                IMC       Friday  \n",
       "73286                VMC     Thursday  \n",
       "73313                VMC     Thursday  \n",
       "73321                VMC     Saturday  \n",
       "73329                VMC       Sunday  \n",
       "...                  ...          ...  \n",
       "90275                NaN      Tuesday  \n",
       "90293                IMC      Tuesday  \n",
       "90295                VMC    Wednesday  \n",
       "90328                NaN      Tuesday  \n",
       "90335                NaN     Thursday  \n",
       "\n",
       "[489 rows x 24 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a new dataframe variable so we could the filtered dataset of the original aviation dataset,\n",
    "# we can compare the data we seperated. Still with us after that?\n",
    "df_filterered = df_filtered\n",
    "\n",
    "# Filtering the filtered dataset of the original aviation dataset, we can compare the data we seperated\n",
    "df_filterered = df_filterered.loc[df['Aircraft.damage'] == 'Substantial']\n",
    "df_filterered = df_filterered.loc[df['Total.Uninjured'] > 0]\n",
    "df_filterered = df_filterered.loc[df['Number.of.Engines'] == 2] \n",
    "\n",
    "# Woow, its the new dataframe! Again, would have used matplotlib here, but naaaah. Let's not please. \n",
    "df_filterered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda1e8f",
   "metadata": {},
   "source": [
    "## Alriight, now that we've done as much filtering we believe we need, we move on to filtering the remaining columns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac4e9870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7307 items.\n",
      "7302 items.\n",
      "The original 670 makes have been reduced to 433 makes.\n"
     ]
    }
   ],
   "source": [
    "# Filter for foreign locations not noted as foreign using the 'OF' state code in Location\n",
    "df_filtered['State_Code'] = df_filtered['Location'].str.slice(-2)\n",
    "df_filtered = df_filtered.loc[df_filtered['State_Code'] != 'OF']\n",
    "print(f\"{len(df_filtered)} items.\")\n",
    "\n",
    "# Drop rows that are missing latitude coordinates (also captures missing Longitude)\n",
    "df_filtered.dropna(subset=['Latitude'], inplace=True)\n",
    "print(f\"{len(df_filtered)} items.\")\n",
    "\n",
    "#Converting latitude and longitude from Degrees, Minutes, and Seconds to Decimal Degrees\n",
    "\n",
    "df_filtered.dropna(subset=['Latitude', 'Longitude'], inplace=True)\n",
    "\n",
    "def convert_latitude(x):\n",
    "    degrees = float(x[:2])\n",
    "    minutes = float(x[2:4])\n",
    "    seconds = float(x[4:6])\n",
    "    return degrees + minutes/60 + seconds/3600\n",
    "\n",
    "df_filtered[\"new_lats\"] = df_filtered['Latitude'].map(convert_latitude)\n",
    "\n",
    "def convert_longitude(x):\n",
    "    degrees = float(x[:3])\n",
    "    minutes = float(x[3:5])\n",
    "    seconds = float(x[5:7])\n",
    "    return -(degrees + minutes/60 + seconds/3600)\n",
    "\n",
    "df_filtered[\"new_longs\"] = df_filtered['Longitude'].map(convert_longitude)\n",
    "\n",
    "# Record original makes for later comparison\n",
    "Original_makes = len(df_filtered['Make'].unique())\n",
    "# These map functions will clean the 'Make' column, A-C\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Aerofab\" if x.lower().strip()[:7]==\"aerofab\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Aeroprakt\" if x.lower().strip()[:9]==\"aeroprakt\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Aeropro\" if x.lower().strip()[:7]==\"aeropro\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Aerostar\" if x.lower().strip()[:8]==\"aerostar\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Aerostar\" if x.lower().strip()[:3]==\"s c\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Aerotek\" if x.lower().strip()[:7]==\"aerotek\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Air Tractor\" if x.lower().strip()[:11]==\"air tractor\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Airbus\" if x.lower().strip()[:6]==\"airbus\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Airbus\" if x.lower().strip()[:5]==\"fouga\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Aircraft Mfg\" if x.lower().strip()[:12]==\"aircraft mfg\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"American Champion\" if x.lower().strip()[:17]==\"american champion\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"American Legend\" if x.lower().strip()[:15]==\"american legend\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Arion\" if x.lower().strip()[:5]==\"arion\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Aviat\" if x.lower().strip()[:5]==\"aviat\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Avions\" if x.lower().strip()[:6]==\"avions\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"BAE\" if x.lower().strip()[:3]==\"bae\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Boeing\" if x.lower().strip()[:6]==\"boeing\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Boeing\" if x.lower().strip()[:9]==\"mcdonnell\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Boeing\" if x.lower().strip()[:7]==\"douglas\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Boeing\" if x.lower().strip()[:8]==\"rockwell\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Bombardier\" if x.lower().strip()[:10]==\"bombardier\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Bombardier\" if x.lower().strip()[:5]==\"gates\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Bombardier\" if x.lower().strip()[:7]==\"learjet\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Bombardier\" if x.lower().strip()[:8]==\"canadair\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"BAE\" if x.lower().strip()[:12]==\"british aero\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Britten-Norman\" if x.lower().strip()[:7]==\"britten\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Bucker\" if x.lower().strip()[:6]==\"bucker\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Cirrus\" if x.lower().strip()[:6]==\"cirrus\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Convair\" if x.lower().strip()[:12]==\"consolidated\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"CubCrafters\" if x.lower().strip()[:3]==\"cub\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Czech\" if x.lower().strip()[:5]==\"czech\" else x)\n",
    "# These map functions will clean the 'Make' column, D-N\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Daher\" if x.lower().strip()[:3]==\"s.o\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Daher\" if x.lower().strip()[:3]==\"soc\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Dassault\" if x.lower().strip()[:8]==\"dassault\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"De Havilland\" if x.lower().strip()[:6]==\"de hav\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"De Havilland\" if x.lower().strip()[:5]==\"dehav\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Diamond\" if x.lower().strip()[:7]==\"diamond\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Eclipse\" if x.lower().strip()[:7]==\"eclipse\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Embraer\" if x.lower().strip()[:7]==\"embraer\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Evektor\" if x.lower().strip()[:7]==\"evektor\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Evolution\" if x.lower().strip()[:9]==\"evolution\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Extra\" if x.lower().strip()[:5]==\"extra\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Fairchild\" if x.lower().strip()[:9]==\"fairchild\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Fantasy Air\" if x.lower().strip()[:7]==\"fantasy\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Flight Design\" if x.lower().strip()[:8]==\"flight d\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Flightstar\" if x.lower().strip()[:7]==\"flights\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"FPNA\" if x.lower().strip()[:4]==\"fpna\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Glasair\" if x.lower().strip()[:7]==\"glasair\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Golden Circle\" if x.lower().strip()[:8]==\"golden c\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Gulfstream\" if x.lower().strip()[:10]==\"gulfstream\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Gulfstream\" if x.lower().strip()[:3]==\"iai\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Honda\" if x.lower().strip()[:5]==\"honda\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Jabiru\" if x.lower().strip()[:6]==\"jabiru\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Lancair\" if x.lower().strip()[:7]==\"lancair\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Maxair\" if x.lower().strip()[:6]==\"maxair\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Meyers\" if x.lower().strip()[:6]==\"meyers\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Mooney\" if x.lower().strip()[:6]==\"mooney\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"M-Squared\" if x.lower().strip()[:9]==\"m-squared\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Nanchang\" if x.lower().strip()[:8]==\"nanchang\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Northrop Grumman\" if x.lower().strip()[:7]==\"grumman\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Northrop Grumman\" if x.lower().strip()[:8]==\"northrop\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"North American\" if x.lower().strip()[:8]==\"north am\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"North Wing\" if x.lower().strip()[:7]==\"north w\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"North Wing\" if x.lower().strip()[:6]==\"northw\" else x)\n",
    "# These map functions will clean the 'Make' column, N-Z\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Orlican\" if x.lower().strip()[:7]==\"orlican\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Phantom\" if x.lower().strip()[:7]==\"phantom\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Pilatus\" if x.lower().strip()[:7]==\"pilatus\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Piper\" if x.lower().strip()[:9]==\"new piper\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Piper\" if x.lower().strip()[:5]==\"piper\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Pipistrel\" if x.lower().strip()[:4]==\"pipi\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Pitts\" if x.lower().strip()[:5]==\"pitts\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Pzl Okecie\" if x.lower().strip()[:3]==\"pzl\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Quad City\" if x.lower().strip()[:4]==\"quad\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Quest\" if x.lower().strip()[:5]==\"quest\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Quicksilver\" if x.lower().strip()[:5]==\"quick\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Rans\" if x.lower().strip()[:4]==\"rans\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Remos\" if x.lower().strip()[:5]==\"remos\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Rockwell\" if x.lower().strip()[:8]==\"rockwell\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Ryan\" if x.lower().strip()[:4]==\"ryan\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Scoda\" if x.lower().strip()[:5]==\"scoda\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Short\" if x.lower().strip()[:5]==\"short\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Stearman\" if x.lower().strip()[:8]==\"stearman\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Taylorcraft\" if x.lower().strip()[:7]==\"taylorc\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:6]==\"cessna\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:4]==\"rath\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:4]==\"rayt\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:7]==\"textron\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:5]==\"beech\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Textron\" if x.lower().strip()[:6]==\"hawker\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"TL Ultralight\" if x.lower().strip()[:2]==\"tl\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Vans\" if x.lower().strip()[:4]==\"vans\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Waco\" if x.lower().strip()[:4]==\"waco\" else x)\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: \"Zlin\" if x.lower().strip()[:4]==\"zlin\" else x)\n",
    "\n",
    "# Show the amount of consolidation in makes\n",
    "print(f\"The original {Original_makes} makes have been reduced to {len(df_filtered['Make'].unique())} makes.\")\n",
    "\n",
    "# Change \"NaN\" to 'None' or 'Unknown', as appropriate\n",
    "df_filtered['Injury.Severity'].fillna('None', inplace=True)\n",
    "df_filtered['Aircraft.damage'].fillna('Unknown', inplace=True)\n",
    "df_filtered['Purpose.of.flight'].fillna('Unknown', inplace=True)\n",
    "df_filtered['Engine.Type'].fillna('Unknown', inplace=True)\n",
    "df_filtered['FAR.Description'].fillna('Unknown', inplace=True)\n",
    "df_filtered['Number.of.Engines'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# This will convert all 'unknown' type entries to 'Unknown' in the Air.carrier field\n",
    "df_filtered['Air.carrier'].fillna('Unknown', inplace=True)\n",
    "df_filtered['Air.carrier'] = df_filtered['Air.carrier'].astype(str).map(\n",
    "    lambda x: \"Unknown\" if x.lower().strip()[:3]==\"unk\" else x)\n",
    "\n",
    "# This will convert all 'unknown' type entries to 'Unknown' in the Weather.Condition field\n",
    "df_filtered['Weather.Condition'].fillna('Unknown', inplace=True)\n",
    "df_filtered['Weather.Condition'] = df_filtered['Weather.Condition'].astype(str).map(\n",
    "    lambda x: \"Unknown\" if x.lower().strip()[:3]==\"unk\" else x)\n",
    "\n",
    "# Put all Makes into Title case, for readability\n",
    "df_filtered['Make'] = df_filtered['Make'].map(lambda x: x.title())\n",
    "\n",
    "# Use dt functions to extract year and month and create new columns\n",
    "df_filtered['Year'] = df['Event.Date'].dt.year\n",
    "df_filtered['Month'] = df['Event.Date'].dt.month\n",
    "\n",
    "# Create a new column to simplify the large jet analysis\n",
    "separate_large_jets = [\"Airbus\", \"Boeing\", \"Embraer\"]\n",
    "df_filtered['Large_Jets'] = df_filtered['Make'].map(lambda x: \"Other\" if x not in separate_large_jets else x)\n",
    "\n",
    "# Create a new column to simplify the large jet analysis\n",
    "separate_small_jets = [\"Bombardier\", \"Dassault\", \"Gulfstream\", \"Honda\", \"Textron\"]\n",
    "df_filtered['Small_Jets'] = df_filtered['Make'].map(lambda x: \"Other\" if x not in separate_small_jets else x)\n",
    "\n",
    "# Create a new column summing fatal and serious injuries\n",
    "df_filtered['Major_Injuries'] = df_filtered['Total.Fatal.Injuries'] + df_filtered['Total.Serious.Injuries']\n",
    "# Write to a new CSV file\n",
    "df_filtered.to_csv('Filtered_Aviation_Data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
